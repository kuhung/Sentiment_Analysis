{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from Attention_layer import  Attention_layer\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 s, sys: 256 ms, total: 14.8 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "GLOVE_DIR = \"../input\"\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10326</td>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10327</td>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10328</td>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10329</td>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10330</td>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id10326  The room was kind of clean but had a VERY stro...   \n",
       "1  id10327  I stayed at the Crown Plaza April -- - April -...   \n",
       "2  id10328  I booked this hotel through Hotwire at the low...   \n",
       "3  id10329  Stayed here with husband and sons on the way t...   \n",
       "4  id10330  My girlfriends and I stayed here to celebrate ...   \n",
       "\n",
       "        Browser_Used Device_Used Is_Response  target  \n",
       "0               Edge      Mobile   not happy       0  \n",
       "1  Internet Explorer      Mobile   not happy       0  \n",
       "2            Mozilla      Tablet   not happy       0  \n",
       "3   InternetExplorer     Desktop       happy       1  \n",
       "4               Edge      Tablet   not happy       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target']=train['Is_Response'].apply(lambda x: 0 if x=='not happy' else 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 224 ms, total: 10.9 s\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train['Description'])\n",
    "sequences = tokenizer.texts_to_sequences(train['Description'])\n",
    "word_index = tokenizer.word_index\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(np.asarray(train['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embedding_matrix: 50579\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print ('Length of embedding_matrix:', embedding_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing and validation set number of positive and negative reviews\n",
      "[  9927.  21219.]\n",
      "[ 2484.  5302.]\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            mask_zero=False,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "print('Traing and validation set number of positive and negative reviews')\n",
    "print (y_train.sum(axis=0))\n",
    "print (y_val.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 1000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 1000, 100)     5057900     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1000, 100)     10100       embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "globalmaxpooling1d_1 (GlobalMaxP (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100)           0           globalmaxpooling1d_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             202         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 5,068,202\n",
      "Trainable params: 10,302\n",
      "Non-trainable params: 5,057,900\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## MLP\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "dense_1 = Dense(100,activation='relu')(embedded_sequences)\n",
    "max_pooling = GlobalMaxPooling1D()(dense_1)\n",
    "\n",
    "drop_3 = Dropout(0.2)(max_pooling)\n",
    "dense_2 = Dense(2, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(sequence_input, dense_2)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31146 samples, validate on 7786 samples\n",
      "Epoch 1/10\n",
      "31146/31146 [==============================] - 35s - loss: 0.5642 - acc: 0.7247 - val_loss: 0.3574 - val_acc: 0.84360s - loss: 0.5671 - acc: 0.7\n",
      "Epoch 2/10\n",
      "31146/31146 [==============================] - 33s - loss: 0.3915 - acc: 0.8251 - val_loss: 0.3286 - val_acc: 0.8574\n",
      "Epoch 3/10\n",
      "31146/31146 [==============================] - 33s - loss: 0.3603 - acc: 0.8429 - val_loss: 0.3273 - val_acc: 0.8585\n",
      "Epoch 4/10\n",
      "31146/31146 [==============================] - 33s - loss: 0.3407 - acc: 0.8531 - val_loss: 0.3111 - val_acc: 0.8698\n",
      "Epoch 5/10\n",
      "31146/31146 [==============================] - 33s - loss: 0.3312 - acc: 0.8571 - val_loss: 0.3043 - val_acc: 0.8699\n",
      "Epoch 6/10\n",
      "31146/31146 [==============================] - 35s - loss: 0.3232 - acc: 0.8610 - val_loss: 0.2983 - val_acc: 0.8767\n",
      "Epoch 7/10\n",
      "31146/31146 [==============================] - 34s - loss: 0.3166 - acc: 0.8634 - val_loss: 0.2964 - val_acc: 0.8745\n",
      "Epoch 8/10\n",
      "31146/31146 [==============================] - 35s - loss: 0.3095 - acc: 0.8695 - val_loss: 0.2991 - val_acc: 0.8743\n",
      "Epoch 9/10\n",
      "31146/31146 [==============================] - 34s - loss: 0.3061 - acc: 0.8716 - val_loss: 0.3225 - val_acc: 0.8628\n",
      "Epoch 10/10\n",
      "31146/31146 [==============================] - 34s - loss: 0.3008 - acc: 0.8730 - val_loss: 0.2951 - val_acc: 0.8762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f034144d630>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          nb_epoch=10, batch_size=200)\n",
    "\n",
    "model.save('../output/MLP.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('../output/MLP.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 1000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 1000, 100)     5057900     input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 1000, 200)     160800      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "attention_layer_1 (Attention_lay (None, 200)           40200       bidirectional_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           20100       attention_layer_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             202         dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 5,279,202\n",
      "Trainable params: 221,302\n",
      "Non-trainable params: 5,057,900\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Lstm with attetion\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_gru = Bidirectional(LSTM(100, return_sequences=True))(embedded_sequences)\n",
    "l_att = Attention_layer()(l_gru)\n",
    "dense_1 = Dense(100,activation='tanh')(l_att)\n",
    "dense_2 = Dense(2, activation='softmax')(dense_1)\n",
    "\n",
    "model = Model(sequence_input, dense_2)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot_ng in /home/kuhung/miniconda3/envs/NLP/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in /home/kuhung/miniconda3/envs/NLP/lib/python3.6/site-packages (from pydot_ng)\n",
      "E: 无法打开锁文件 /var/lib/dpkg/lock - open (13: 权限不够)\n",
      "E: 无法对状态列表目录加锁(/var/lib/dpkg/)，请查看您是否正以 root 用户运行？\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"476pt\" viewBox=\"0.00 0.00 448.00 476.00\" width=\"448pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-472 444,-472 444,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140593422434824 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140593422434824</title>\n",
       "<polygon fill=\"none\" points=\"85.5,-421 85.5,-467 354.5,-467 354.5,-421 85.5,-421\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"148\" y=\"-440.3\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"210.5,-421 210.5,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-451.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"210.5,-444 265.5,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238\" y=\"-428.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"265.5,-421 265.5,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-451.8\">(None, 1000)</text>\n",
       "<polyline fill=\"none\" points=\"265.5,-444 354.5,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-428.8\">(None, 1000)</text>\n",
       "</g>\n",
       "<!-- 140593422134968 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140593422134968</title>\n",
       "<polygon fill=\"none\" points=\"53.5,-337 53.5,-383 386.5,-383 386.5,-337 53.5,-337\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134\" y=\"-356.3\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"214.5,-337 214.5,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-367.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"214.5,-360 269.5,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242\" y=\"-344.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"269.5,-337 269.5,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328\" y=\"-367.8\">(None, 1000)</text>\n",
       "<polyline fill=\"none\" points=\"269.5,-360 386.5,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328\" y=\"-344.8\">(None, 1000, 100)</text>\n",
       "</g>\n",
       "<!-- 140593422434824&#45;&gt;140593422134968 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140593422434824-&gt;140593422134968</title>\n",
       "<path d=\"M220,-420.593C220,-412.118 220,-402.297 220,-393.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"223.5,-393.096 220,-383.096 216.5,-393.096 223.5,-393.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140593421982296 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140593421982296</title>\n",
       "<polygon fill=\"none\" points=\"-0.5,-253 -0.5,-299 440.5,-299 440.5,-253 -0.5,-253\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134\" y=\"-272.3\">bidirectional_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "<polyline fill=\"none\" points=\"268.5,-253 268.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296\" y=\"-283.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"268.5,-276 323.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296\" y=\"-260.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"323.5,-253 323.5,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382\" y=\"-283.8\">(None, 1000, 100)</text>\n",
       "<polyline fill=\"none\" points=\"323.5,-276 440.5,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"382\" y=\"-260.8\">(None, 1000, 200)</text>\n",
       "</g>\n",
       "<!-- 140593422134968&#45;&gt;140593421982296 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140593422134968-&gt;140593421982296</title>\n",
       "<path d=\"M220,-336.593C220,-328.118 220,-318.297 220,-309.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"223.5,-309.096 220,-299.096 216.5,-309.096 223.5,-309.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140593471147480 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140593471147480</title>\n",
       "<polygon fill=\"none\" points=\"32.5,-169 32.5,-215 407.5,-215 407.5,-169 32.5,-169\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134\" y=\"-188.3\">attention_layer_1: Attention_layer</text>\n",
       "<polyline fill=\"none\" points=\"235.5,-169 235.5,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263\" y=\"-199.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"235.5,-192 290.5,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263\" y=\"-176.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"290.5,-169 290.5,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349\" y=\"-199.8\">(None, 1000, 200)</text>\n",
       "<polyline fill=\"none\" points=\"290.5,-192 407.5,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349\" y=\"-176.8\">(None, 200)</text>\n",
       "</g>\n",
       "<!-- 140593421982296&#45;&gt;140593471147480 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140593421982296-&gt;140593471147480</title>\n",
       "<path d=\"M220,-252.593C220,-244.118 220,-234.297 220,-225.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"223.5,-225.096 220,-215.096 216.5,-225.096 223.5,-225.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140593220377624 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140593220377624</title>\n",
       "<polygon fill=\"none\" points=\"100,-85 100,-131 340,-131 340,-85 100,-85\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151\" y=\"-104.3\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"202,-85 202,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-115.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"202,-108 257,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-92.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"257,-85 257,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.5\" y=\"-115.8\">(None, 200)</text>\n",
       "<polyline fill=\"none\" points=\"257,-108 340,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.5\" y=\"-92.8\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140593471147480&#45;&gt;140593220377624 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140593471147480-&gt;140593220377624</title>\n",
       "<path d=\"M220,-168.593C220,-160.118 220,-150.297 220,-141.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"223.5,-141.096 220,-131.096 216.5,-141.096 223.5,-141.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140593219292184 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140593219292184</title>\n",
       "<polygon fill=\"none\" points=\"100,-1 100,-47 340,-47 340,-1 100,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151\" y=\"-20.3\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"202,-1 202,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-31.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"202,-24 257,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"229.5\" y=\"-8.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"257,-1 257,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.5\" y=\"-31.8\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"257,-24 340,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"298.5\" y=\"-8.8\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 140593220377624&#45;&gt;140593219292184 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140593220377624-&gt;140593219292184</title>\n",
       "<path d=\"M220,-84.5931C220,-76.1177 220,-66.2974 220,-57.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"223.5,-57.0958 220,-47.0959 216.5,-57.0959 223.5,-57.0958\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可视化（在本地可选）\n",
    "\n",
    "! pip install pydot_ng \n",
    "! apt-get install graphviz\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import  model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31146 samples, validate on 7786 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "#model.fit(x_train, y_train, validation_data=(x_val, y_val),nb_epoch=10, batch_size=200)\n",
    "\n",
    "#model.save('../output/LSTM_with_Attetion.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../output/LSTM_with_Attetion.h5',\n",
    "              custom_objects={'Attention_layer':Attention_layer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
